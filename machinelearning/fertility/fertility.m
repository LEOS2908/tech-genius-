clear; close all; clcfprintf('Loading and Visualizing Data ...\n')temp = xlsread('fertility.xlsx');% parameters using for this workout %input_layer_size = size(temp, 2) - 1;hidden_layer_size = 8;hidden_layer_size_1 = 4;num_labels = 2;% parameters using for this workout %% begin preparing data %%temp = temp(randperm(size(temp,1)), :);X = temp(1 : 60, 1 : size(temp, 2) - 1);y = temp(1 : 60, size(temp,2) : end);Xval = temp(61 : 80, 1 : size(temp, 2) - 1);yval = temp(61 : 80, size(temp,2) : end);Xtest = temp(81 : end, 1 : size(temp, 2) - 1);ytest = temp(81 : end, size(temp,2) : end);% finish preparing data %displayData(X);pause;% begin preparing theta %Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size);Theta2 = randInitializeWeights(hidden_layer_size, hidden_layer_size_1);Theta3 = randInitializeWeights(hidden_layer_size_1, num_labels);initial_nn_params = [Theta1(:) ; Theta2(:); Theta3(:)];% finish preparing theta %% Training%lambda = 0;costFunction = @(p) nnCostFunction(p,input_layer_size, hidden_layer_size,                                 hidden_layer_size_1, num_labels, X, y, lambda);                                   options = optimset('MaxIter', 50);[nn_params, cost] = fmincg(costFunction, initial_nn_params, options);% end training %% predicting %Theta1 = reshape(nn_params(1:hidden_layer_size * (input_layer_size + 1)), ...                 hidden_layer_size, (input_layer_size + 1));Theta2 = reshape(nn_params(1 + hidden_layer_size * (input_layer_size + 1):                                hidden_layer_size * (input_layer_size + 1) + ...                               hidden_layer_size_1 * (hidden_layer_size + 1)), ...                 hidden_layer_size_1, (hidden_layer_size + 1));                 Theta3 = reshape(nn_params(1 + hidden_layer_size * (input_layer_size + 1) ...                               + hidden_layer_size_1 * (hidden_layer_size + 1)...                                :end), ...                 num_labels, (hidden_layer_size_1 + 1));                 pred = predict(Theta1, Theta2, Theta3, X);pred = pred - 1;fprintf('\nTraining Set Accuracy: %f\n', mean(double(pred == y)) * 100);% predicting %% time for debugging HORRAYYY!!! :<<<<<< %lambda = 0;[error_train, error_val] = ...    learningCurve(X(1 : size(X, 1), :), y(1 : size(X, 1)), ...                  Xval, yval, ...                  lambda);                                    plot(1:size(X, 1), error_train, 1:size(X, 1), error_val);title('Learning curve for neural network (lambda = 0)')legend('Train', 'Cross Validation')xlabel('Number of training examples')ylabel('Error')pause;%finding lambdaval = choosingthebest(X, y, Xval, yval, 200);[error_train, error_val] = ...    learningCurve(X(1 : size(X, 1), :), y(1 : size(X, 1)), ...                  Xval, yval, ...                  val);                  val            [times, val] = tenary(X, y, Xval, yval); plot(times, val);xlabel('number of iterations');ylabel('lamda value');pause;  plot(1:size(X, 1), error_train, 1:size(X, 1), error_val);title('Learning curve for neural network (lambda)')legend('Train', 'Cross Validation')xlabel('Number of training examples')ylabel('Error')pause;% end time for debugging YAYYYY!!! :>>>>>> %